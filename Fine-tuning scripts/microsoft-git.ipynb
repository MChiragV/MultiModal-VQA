{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11684676,"sourceType":"datasetVersion","datasetId":7333755},{"sourceId":11695544,"sourceType":"datasetVersion","datasetId":7300084}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Installing Dependencies","metadata":{}},{"cell_type":"code","source":"!pip install -U transformers accelerate peft bitsandbytes","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import AutoProcessor, AutoModelForCausalLM, TrainingArguments, Trainer\nfrom peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\nfrom torch.utils.data import Dataset\nfrom PIL import Image\nimport pandas as pd\nimport os\nimport torch.nn as nn\n\n# Device\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Loading the model","metadata":{}},{"cell_type":"code","source":"# Load processor and model\nprocessor = AutoProcessor.from_pretrained(\"microsoft/git-base-vqav2\")\nmodel = AutoModelForCausalLM.from_pretrained(\n    \"microsoft/git-base-vqav2\",\n    device_map={\"\": 0},\n    torch_dtype=torch.float16,\n    load_in_8bit=True\n)\nmodel = prepare_model_for_kbit_training(model)\n\n# Apply LoRA to decoder (only)\nconfig = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    lora_dropout=0.1,\n    bias=\"none\",\n    target_modules=\"all-linear\",\n    task_type=\"CAUSAL_LM\"\n)\nmodel = get_peft_model(model, config)\nmodel.print_trainable_parameters()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Loading the dataset","metadata":{}},{"cell_type":"code","source":"class GitVQADataset(Dataset):\n    def __init__(self, csv_path, image_folder, processor, max_samples=None):\n        self.data = pd.read_csv(csv_path)\n        if max_samples:\n            self.data = self.data[:max_samples]\n        self.image_folder = image_folder\n        self.processor = processor\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        row = self.data.iloc[idx]\n        image_path = os.path.join(self.image_folder, row[\"image_name\"])\n        image = Image.open(image_path).convert(\"RGB\")\n        question = row[\"question\"]\n        answer = row[\"answer\"]\n\n        prompt = question.strip().rstrip(\"?\") + \"?\"\n        inputs = processor(images=image, text=prompt, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=128)\n        labels = processor.tokenizer(answer, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=10).input_ids\n\n        inputs = {k: v.squeeze(0).to(device) for k, v in inputs.items()}  # Ensure inputs are on the same device\n        labels = labels.squeeze(0).to(device)  # Ensure labels are on the same device\n\n        # Create a new tensor instead of in-place modification\n        labels = torch.where(labels == processor.tokenizer.pad_token_id, torch.tensor(-100, device=device), labels)\n\n        inputs[\"labels\"] = labels\n        return inputs\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Paths\nimage_folder = \"/kaggle/input/vr-dataset-filtered/images/images\"\ncsv_path = \"/kaggle/input/vr-dataset-filtered/cleaned_data.csv\"\n\n# Load dataset\ndataset = GitVQADataset(csv_path, image_folder, processor, max_samples=1000)\ntrain_size = int(0.8 * len(dataset))\ntrain_dataset, eval_dataset = torch.utils.data.random_split(dataset, [train_size, len(dataset) - train_size])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"class CustomTrainer(Trainer):\n    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n        # Forward pass through the model\n        outputs = model(**inputs)\n        logits = outputs.logits\n\n        # Compute loss manually\n        labels = inputs.get(\"labels\")\n        loss_fct = nn.CrossEntropyLoss()\n        # Flatten the labels and logits to compute the loss\n        loss = loss_fct(logits.view(-1, logits.size(-1)), labels.view(-1))\n\n        return (loss, outputs) if return_outputs else loss\n\n# Training args\ntraining_args = TrainingArguments(\n    output_dir=\"./git-vqa-lora\",\n    per_device_train_batch_size=4,\n    gradient_accumulation_steps=2,\n    num_train_epochs=5,\n    learning_rate=2e-4,\n    fp16=True,\n    save_total_limit=2,\n    logging_dir=\"./logs\",\n    logging_strategy=\"epoch\",\n    report_to=\"none\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Trainer\ntrainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset,\n    tokenizer=processor.tokenizer\n)\n\n# Train\ntrainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}