# Visual Recognition Mini Project-2: Visual Question Answering(VQA)
## Dataset

## Baseline Evaluation
This directory contains 4 notebooks:
- BLIP.ipynb: This notebook is used to run the BLIP pretrained model.
- LLaVA.ipynb: This notebook is used to run the LLaVA pretrained model.
- Qwen.ipynb: This notebook is used to run the Qwen pretrained model.
- VilBERT.ipynb: This notebook is used to run the VilBERT pretrained model.

## Fine-tuning scripts
This directory contains 6 notebooks:
- blip.ipynb: This notebook is used to run the BLIP fine-tuned model.
- blip2.ipynb: This notebook is used to run the BLIP2 fine-tuned model.
- llava.ipynb: This notebook is used to run the LLaVA fine-tuned model.
- microsoft-git.ipynb: This notebook is used to run the Microsoft Git fine-tuned model.
- phi3.ipynb: This notebook is used to run the Phi3 fine-tuned model.
- qwen.ipynb: This notebook is used to run the Qwen fine-tuned model.

## inference_setup
Please download the files from this directory to test our best fine-tuned model.

- inference.py: This file is used to run our best fine-tuned model on given data.
- requirements.txt: This file contains the requirements to run the inference.py file.


## Contributions
- Sai Venkata Sohith Gutta (IMT202242): Responsible for the directories "Fine-tuning scripts" and "inference_setup".
